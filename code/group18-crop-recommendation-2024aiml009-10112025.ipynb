{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b2243b-954e-44c7-af24-45872d427c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Accuracy: 0.9572\n",
      "Saved: serving_catboost_topN.pkl and training_report_topN.txt\n"
     ]
    }
   ],
   "source": [
    "# train_high_accuracy_top3.py\n",
    "import os, re, warnings, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "DATA_PATH = \"data/AP_data.csv\"\n",
    "DIST_PATH = \"data/AP_district_level_master.csv\"\n",
    "\n",
    "# To push accuracy higher, you can filter to top-N crops (set True & choose N)\n",
    "USE_TOP_N_CLASSES = True\n",
    "TOP_N = 12            # try 10–12 for highest Top-3 on focused classes\n",
    "\n",
    "# If not filtering, mapping tail to \"Other\" usually hurts; keep False for now\n",
    "KEEP_OTHER_CLASS = False\n",
    "\n",
    "TEST_SIZE = 0.25\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Use Bernoulli bootstrap to allow subsample < 1.0\n",
    "CB_PARAMS = dict(\n",
    "    iterations=1200,\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"Accuracy\",\n",
    "    l2_leaf_reg=3,\n",
    "    bootstrap_type=\"Bernoulli\",  # allows subsample\n",
    "    subsample=0.8,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    auto_class_weights=\"Balanced\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "MODEL_OUT = \"serving_catboost_topN.pkl\"\n",
    "REPORT_OUT = \"training_report_topN.txt\"\n",
    "\n",
    "# ===================== LOAD =====================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "dist_master = pd.read_csv(DIST_PATH)\n",
    "\n",
    "df = df.rename(columns={\"Extent\\n(AC)\": \"Farm_Acres\", \"Crop before\": \"Crop_Sown\"})\n",
    "df[\"District\"] = df[\"District\"].replace({\n",
    "    \"Anantapur\": \"Ananthapur\",\n",
    "    \"S.P.S.Nellore\": \"Nellore\",\n",
    "    \"S.P.S. Nellore\": \"Nellore\",\n",
    "    \"Kadapa YSR\": \"Kadapa\"\n",
    "})\n",
    "\n",
    "# Merge district rainfall normals (if available)\n",
    "if {\"District\",\"Kharif_rain\",\"Rabi_rain\",\"Zaid_rain\"}.issubset(dist_master.columns):\n",
    "    rain_df = dist_master[[\"District\",\"Kharif_rain\",\"Rabi_rain\",\"Zaid_rain\"]].drop_duplicates()\n",
    "    df = df.merge(rain_df, on=\"District\", how=\"left\")\n",
    "\n",
    "# Drop non-predictive / ID-like columns\n",
    "drop_cols = [\n",
    "    \"Sl no\",\"Date\",\"Farmer No\",\"Macro/ Micro nutrient\",\"Farmer Name\",\n",
    "    \"Fathers Name\",\"Time\",\"Recommended Sowing Time\",\"Survey No.\",\n",
    "    \"Latitude\",\"Longitude\",\"Farm_Acres\"\n",
    "]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "# Numeric coercion for known messy numeric columns\n",
    "for col in [\"OC\",\"Avail-S\",\"Avail-B\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# ===================== STANDARDIZE SOIL =====================\n",
    "MASTER_SOIL = [\n",
    "    \"Black\",\"Red\",\"Sandy\",\"Loam\",\"Clay\",\"Brown\",\"Yellow\",\"White\",\n",
    "    \"Laterite\",\"Saline\",\"Alkaline\",\"Alluvial\",\"Gravel/Stony\",\"Mixed\",\"Other\"\n",
    "]\n",
    "\n",
    "def _clean_text(s: str) -> str:\n",
    "    s = str(s).lower().strip()\n",
    "    s = re.sub(r\"soil\", \"\", s)\n",
    "    s = re.sub(r\"[^a-z\\s\\+\\-]\", \"\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def standardize_soil(raw: str) -> str:\n",
    "    if not isinstance(raw, str) or not raw.strip():\n",
    "        return \"Unknown\"\n",
    "    txt = _clean_text(raw)\n",
    "    match, score, _ = process.extractOne(txt, MASTER_SOIL, scorer=fuzz.WRatio)\n",
    "    return match if score >= 80 else \"Unknown\"\n",
    "\n",
    "soil_col = \"Soil type\" if \"Soil type\" in df.columns else None\n",
    "if not soil_col:\n",
    "    for c in df.columns:\n",
    "        if c.lower().strip() == \"soil type\":\n",
    "            soil_col = c; break\n",
    "if soil_col:\n",
    "    df[\"Soil_Type_Standard\"] = df[soil_col].apply(standardize_soil)\n",
    "else:\n",
    "    df[\"Soil_Type_Standard\"] = \"Unknown\"\n",
    "\n",
    "# ===================== STANDARDIZE CROP =====================\n",
    "def standardize_crop(raw: str) -> str:\n",
    "    if not isinstance(raw, str) or not raw.strip():\n",
    "        return \"Other\"\n",
    "    txt = raw.lower()\n",
    "    aliases = {\n",
    "        \"paddy\":\"Rice\",\"vari\":\"Rice\",\"rice\":\"Rice\",\n",
    "        \"maize\":\"Maize\",\"sweetcorn\":\"Maize\",\n",
    "        \"ground nut\":\"Groundnut\",\"groundnut\":\"Groundnut\",\"g.nut\":\"Groundnut\",\n",
    "        \"cotton\":\"Cotton\",\"castor\":\"Castor\",\"sesamum\":\"Sesame\",\"sesame\":\"Sesame\",\n",
    "        \"sunflower\":\"Sunflower\",\"soyabean\":\"Soyabean\",\"soybean\":\"Soyabean\",\n",
    "        \"chilli\":\"Chilli\",\"chillies\":\"Chilli\",\"mirchi\":\"Chilli\",\n",
    "        \"tomato\":\"Tomato\",\"brinjal\":\"Brinjal\",\"okra\":\"Okra\",\"benda\":\"Okra\",\n",
    "        \"ragi\":\"Ragi\",\"sorghum\":\"Sorghum\",\"jowar\":\"Sorghum\",\"jonna\":\"Sorghum\",\n",
    "        \"bajra\":\"Pearl Millet\",\"korra\":\"Foxtail Millet\"\n",
    "    }\n",
    "    for k,v in aliases.items():\n",
    "        if k in txt: return v\n",
    "    return raw.title()\n",
    "\n",
    "df[\"Crop_Sown_Standard\"] = df[\"Crop_Sown\"].apply(standardize_crop)\n",
    "\n",
    "# ===================== FEATURE SET =====================\n",
    "num_cols = [c for c in [\n",
    "    \"pH\",\"EC\",\"OC\",\"Avail-P\",\"Exch-K\",\"Avail-Ca\",\"Avail-Mg\",\"Avail-S\",\n",
    "    \"Avail-Zn\",\"Avail-B\",\"Avail-Fe\",\"Avail-Cu\",\"Avail-Mn\",\n",
    "    \"Kharif_rain\",\"Rabi_rain\",\"Zaid_rain\"\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_cols = [c for c in [\"District\",\"Soil_Type_Standard\"] if c in df.columns]\n",
    "target = \"Crop_Sown_Standard\"\n",
    "\n",
    "# Impute numerics (median)\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(df[c].median())\n",
    "\n",
    "# ===================== INTERACTIONS (safe) =====================\n",
    "def safe_mul(a, b):\n",
    "    return (pd.to_numeric(a, errors=\"coerce\").fillna(0) *\n",
    "            pd.to_numeric(b, errors=\"coerce\").fillna(0))\n",
    "\n",
    "def add_interactions(ddf: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = ddf.copy()\n",
    "    if set([\"pH\",\"EC\"]).issubset(out.columns):\n",
    "        out[\"pH_x_EC\"] = safe_mul(out[\"pH\"], out[\"EC\"])\n",
    "    if set([\"OC\",\"Avail-P\"]).issubset(out.columns):\n",
    "        out[\"OC_x_AvailP\"] = safe_mul(out[\"OC\"], out[\"Avail-P\"])\n",
    "    if set([\"OC\",\"Exch-K\"]).issubset(out.columns):\n",
    "        out[\"OC_x_ExchK\"] = safe_mul(out[\"OC\"], out[\"Exch-K\"])\n",
    "    if set([\"pH\",\"Avail-Ca\"]).issubset(out.columns):\n",
    "        out[\"pH_x_AvailCa\"] = safe_mul(out[\"pH\"], out[\"Avail-Ca\"])\n",
    "    if set([\"EC\",\"Avail-Fe\"]).issubset(out.columns):\n",
    "        out[\"EC_x_AvailFe\"] = safe_mul(out[\"EC\"], out[\"Avail-Fe\"])\n",
    "    return out\n",
    "\n",
    "df = add_interactions(df)\n",
    "extra_nums = [\"pH_x_EC\",\"OC_x_AvailP\",\"OC_x_ExchK\",\"pH_x_AvailCa\",\"EC_x_AvailFe\"]\n",
    "num_cols = [c for c in num_cols + extra_nums if c in df.columns]\n",
    "\n",
    "# ===================== CLASS SPACE (Top-N option) =====================\n",
    "if USE_TOP_N_CLASSES:\n",
    "    top_classes = df[target].value_counts().head(TOP_N).index\n",
    "    df = df[df[target].isin(top_classes)].copy()\n",
    "else:\n",
    "    if not KEEP_OTHER_CLASS:\n",
    "        vc = df[target].value_counts()\n",
    "        keep = vc[vc >= 10].index\n",
    "        df = df[df[target].isin(keep)].copy()\n",
    "\n",
    "# ===================== CLEAN TYPES / NAs =====================\n",
    "df = df[df[target].notna()].copy()\n",
    "\n",
    "# Categorical columns → string, fill NaN with \"Unknown\"\n",
    "for c in cat_cols:\n",
    "    if c not in df.columns:\n",
    "        df[c] = \"Unknown\"\n",
    "    df[c] = df[c].astype(\"string\").fillna(\"Unknown\")\n",
    "\n",
    "# Numeric columns → float, fill NaN with 0 (already median-imputed, just in case)\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0).astype(float)\n",
    "\n",
    "# ===================== BUILD X/y =====================\n",
    "X = df[num_cols + cat_cols].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# CatBoost categorical feature indices (by position in X)\n",
    "cat_feature_indices = [X.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "# Pools\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_feature_indices)\n",
    "test_pool  = Pool(X_test,  y_test,  cat_features=cat_feature_indices)\n",
    "\n",
    "# ===================== TRAIN CATBOOST =====================\n",
    "cb = CatBoostClassifier(**CB_PARAMS)\n",
    "cb.fit(train_pool, eval_set=test_pool, verbose=False)\n",
    "\n",
    "# ===================== EVALUATION (Top-3 ONLY) =====================\n",
    "# Probabilities & classes\n",
    "probs = cb.predict_proba(X_test)          # shape: [n_samples, n_classes]\n",
    "classes = cb.classes_                     # array of class labels (strings)\n",
    "\n",
    "# For Top-3 accuracy, align probs to integer labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y)                                 # fit on all training labels\n",
    "y_true_int = le.transform(y_test)\n",
    "# Align columns: CatBoost class order → LabelEncoder class order\n",
    "order = [np.where(classes == c)[0][0] for c in le.classes_]\n",
    "probs_aligned = probs[:, order]\n",
    "\n",
    "# Top-3 accuracy\n",
    "acc_top3 = top_k_accuracy_score(y_true_int, probs_aligned, k=3)\n",
    "\n",
    "# ===================== SAVE MODEL & REPORT =====================\n",
    "joblib.dump(\n",
    "    {\"model\": cb, \"feature_names\": list(X.columns), \"cat_idx\": cat_feature_indices},\n",
    "    MODEL_OUT\n",
    ")\n",
    "\n",
    "with open(REPORT_OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Top-3 Accuracy: {acc_top3:.4f}\\n\")\n",
    "    f.write(f\"Classes: {list(le.classes_)}\\n\")\n",
    "    f.write(f\"Features: {list(X.columns)}\\n\")\n",
    "    f.write(f\"Categorical features: {cat_cols}\\n\")\n",
    "    f.write(f\"Params: {CB_PARAMS}\\n\")\n",
    "\n",
    "print(\"Top-3 Accuracy:\", round(acc_top3, 4))\n",
    "print(\"Saved:\", MODEL_OUT, \"and\", REPORT_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c3d305-f481-42e7-8857-9bde746f1119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
