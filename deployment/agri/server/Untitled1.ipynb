{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6a73b8-a72f-4b19-9e89-8ef50d99a39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RandomForest (tuned) ===\n",
      "Test Accuracy: 0.6287\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Banana       0.00      0.00      0.00        10\n",
      "Banana/Coconut       0.42      0.38      0.40        13\n",
      "    Black Gram       0.62      0.43      0.51        35\n",
      "    Cashew Nut       0.80      0.36      0.50        11\n",
      "        Chilli       0.43      0.41      0.42        29\n",
      "        Citrus       0.73      0.79      0.76        28\n",
      "       Coconut       0.30      0.17      0.21        18\n",
      "        Cotton       0.57      0.54      0.55       119\n",
      "        Cowpea       0.57      0.92      0.71        52\n",
      "     Groundnut       0.57      0.80      0.66       152\n",
      "    Horse Gram       0.20      0.08      0.11        13\n",
      "         Maize       0.53      0.61      0.57        92\n",
      "         Mango       0.00      0.00      0.00         8\n",
      "      Oil Palm       0.11      0.10      0.11        10\n",
      "         Other       0.55      0.45      0.50       124\n",
      "     Pigeonpea       0.40      0.12      0.19        16\n",
      "        Potato       0.50      0.09      0.15        11\n",
      "         Pulse       0.83      0.95      0.88        20\n",
      "          Rice       0.77      0.86      0.82       359\n",
      "        Sesame       1.00      0.45      0.62        11\n",
      "       Sorghum       0.56      0.26      0.36        19\n",
      "    Sugar Cane       0.50      0.20      0.29        15\n",
      "       Tobacco       1.00      0.22      0.36         9\n",
      "        Tomato       0.00      0.00      0.00        20\n",
      "      Turmeric       0.38      0.30      0.33        10\n",
      "\n",
      "      accuracy                           0.63      1204\n",
      "     macro avg       0.49      0.38      0.40      1204\n",
      "  weighted avg       0.60      0.63      0.60      1204\n",
      "\n",
      "\n",
      "=== GradientBoosting (tuned) ===\n",
      "Test Accuracy: 0.6038\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Banana       0.00      0.00      0.00        10\n",
      "Banana/Coconut       0.60      0.46      0.52        13\n",
      "    Black Gram       0.56      0.40      0.47        35\n",
      "    Cashew Nut       0.33      0.18      0.24        11\n",
      "        Chilli       0.44      0.41      0.43        29\n",
      "        Citrus       0.66      0.75      0.70        28\n",
      "       Coconut       0.25      0.11      0.15        18\n",
      "        Cotton       0.55      0.55      0.55       119\n",
      "        Cowpea       0.58      0.77      0.66        52\n",
      "     Groundnut       0.56      0.77      0.65       152\n",
      "    Horse Gram       0.50      0.15      0.24        13\n",
      "         Maize       0.54      0.57      0.55        92\n",
      "         Mango       0.00      0.00      0.00         8\n",
      "      Oil Palm       0.20      0.20      0.20        10\n",
      "         Other       0.51      0.41      0.46       124\n",
      "     Pigeonpea       0.40      0.12      0.19        16\n",
      "        Potato       0.12      0.09      0.11        11\n",
      "         Pulse       0.85      0.85      0.85        20\n",
      "          Rice       0.74      0.83      0.78       359\n",
      "        Sesame       0.57      0.36      0.44        11\n",
      "       Sorghum       0.67      0.32      0.43        19\n",
      "    Sugar Cane       0.40      0.27      0.32        15\n",
      "       Tobacco       0.33      0.22      0.27         9\n",
      "        Tomato       0.43      0.15      0.22        20\n",
      "      Turmeric       0.50      0.30      0.38        10\n",
      "\n",
      "      accuracy                           0.60      1204\n",
      "     macro avg       0.45      0.37      0.39      1204\n",
      "  weighted avg       0.58      0.60      0.58      1204\n",
      "\n",
      "\n",
      "Winner: RandomForest (tuned) → Test Accuracy: 0.6287\n",
      "RF best params: {'clf__max_depth': 20, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 500}\n",
      "GB best params: {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 250}\n",
      "\n",
      "Saved: tuning_summary.csv, serving_pipeline_tuned.pkl\n"
     ]
    }
   ],
   "source": [
    "import re, warnings, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- Load data ----------\n",
    "DATA_PATH = \"data/AP_data.csv\"                       # adjust path if needed\n",
    "DIST_PATH = \"data/AP_district_level_master.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "dist_master = pd.read_csv(DIST_PATH)\n",
    "\n",
    "df.rename(columns={\"Extent\\n(AC)\":\"Farm_Acres\",\"Crop before\":\"Crop_Sown\"}, inplace=True)\n",
    "df[\"District\"] = df[\"District\"].replace({\n",
    "    \"Anantapur\": \"Ananthapur\",\n",
    "    \"S.P.S.Nellore\": \"Nellore\",\n",
    "    \"S.P.S. Nellore\": \"Nellore\",\n",
    "    \"Kadapa YSR\": \"Kadapa\"\n",
    "})\n",
    "\n",
    "rain_df = dist_master[[\"District\",\"Kharif_rain\",\"Rabi_rain\",\"Zaid_rain\"]].drop_duplicates()\n",
    "df = df.merge(rain_df, on=\"District\", how=\"left\")\n",
    "\n",
    "# Drop IDs / timestamps / free-text\n",
    "drop_cols = [\"Sl no\",\"Date\",\"Farmer No\",\"Macro/ Micro nutrient\",\"Farmer Name\",\"Fathers Name\",\"Time\",\n",
    "             \"Recommended Sowing Time\",\"Season\",\"Farm_Acres\",\"Survey No.\",\"Latitude\",\"Longitude\"]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "# Coerce numeric-ish text\n",
    "for col in [\"OC\",\"Avail-S\",\"Avail-B\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# ---------- Soil normalization (light) ----------\n",
    "MASTER_SOIL = [\"Black\",\"Red\",\"Sandy\",\"Loam\",\"Clay\",\"Brown\",\"Yellow\",\"White\",\"Laterite\",\n",
    "               \"Saline\",\"Alkaline\",\"Alluvial\",\"Gravel/Stony\",\"Mixed\",\"Other\"]\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s).lower().strip()\n",
    "    s = re.sub(r\"soil\", \"\", s)\n",
    "    s = re.sub(r\"[^a-z\\s\\+\\-]\", \"\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def standardize_soil(raw: str) -> str:\n",
    "    if not isinstance(raw, str) or not raw.strip(): return \"Other\"\n",
    "    txt = clean_text(raw)\n",
    "    match, score, _ = process.extractOne(txt, MASTER_SOIL, scorer=fuzz.WRatio)\n",
    "    return match if score >= 80 else \"Other\"\n",
    "\n",
    "if \"Soil type\" in df.columns:\n",
    "    df[\"Soil_Type_Standard\"] = df[\"Soil type\"].apply(standardize_soil)\n",
    "else:\n",
    "    alt = [c for c in df.columns if c.lower().strip() == \"soil type\"]\n",
    "    if alt:\n",
    "        df[\"Soil_Type_Standard\"] = df[alt[0]].apply(standardize_soil)\n",
    "\n",
    "# ---------- Crop normalization (simple aliases) ----------\n",
    "def standardize_crop(raw: str) -> str:\n",
    "    if not isinstance(raw, str) or not raw.strip(): return \"Other\"\n",
    "    txt = raw.lower()\n",
    "    aliases = {\n",
    "        \"paddy\":\"Rice\",\"vari\":\"Rice\",\"rice\":\"Rice\",\n",
    "        \"maize\":\"Maize\",\"sweetcorn\":\"Maize\",\n",
    "        \"ground nut\":\"Groundnut\",\"groundnut\":\"Groundnut\",\"g.nut\":\"Groundnut\",\n",
    "        \"cotton\":\"Cotton\",\"castor\":\"Castor\",\"sesamum\":\"Sesame\",\"sesame\":\"Sesame\",\n",
    "        \"sunflower\":\"Sunflower\",\"soyabean\":\"Soyabean\",\"soybean\":\"Soyabean\",\n",
    "        \"chilli\":\"Chilli\",\"chillies\":\"Chilli\",\"mirchi\":\"Chilli\",\n",
    "        \"tomato\":\"Tomato\",\"brinjal\":\"Brinjal\",\"okra\":\"Okra\",\"benda\":\"Okra\",\n",
    "        \"ragi\":\"Ragi\",\"sorghum\":\"Sorghum\",\"jowar\":\"Sorghum\",\"jonna\":\"Sorghum\",\n",
    "        \"bajra\":\"Pearl Millet\",\"korra\":\"Foxtail Millet\"\n",
    "    }\n",
    "    for k,v in aliases.items():\n",
    "        if k in txt: return v\n",
    "    return raw.title()\n",
    "\n",
    "df[\"Crop_Sown_Standard\"] = df[\"Crop_Sown\"].apply(standardize_crop)\n",
    "\n",
    "# keep top 25 classes, rest -> \"Other\"\n",
    "top_classes = df[\"Crop_Sown_Standard\"].value_counts().head(25).index\n",
    "df[\"Crop_Sown_Standard\"] = np.where(df[\"Crop_Sown_Standard\"].isin(top_classes),\n",
    "                                    df[\"Crop_Sown_Standard\"], \"Other\")\n",
    "\n",
    "# ---------- Features ----------\n",
    "num_cols = [c for c in [\n",
    "    \"pH\",\"EC\",\"OC\",\"Avail-P\",\"Exch-K\",\"Avail-Ca\",\"Avail-Mg\",\"Avail-S\",\n",
    "    \"Avail-Zn\",\"Avail-B\",\"Avail-Fe\",\"Avail-Cu\",\"Avail-Mn\",\n",
    "    \"Kharif_rain\",\"Rabi_rain\",\"Zaid_rain\"\n",
    "] if c in df.columns]\n",
    "cat_cols = [c for c in [\"District\",\"Soil_Type_Standard\"] if c in df.columns]\n",
    "target = \"Crop_Sown_Standard\"\n",
    "\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(df[c].median())\n",
    "\n",
    "df = df[df[target].notna()].copy()\n",
    "X = df[num_cols + cat_cols]\n",
    "y = df[target]\n",
    "\n",
    "# ensure stratifyable (drop classes with <2 samples)\n",
    "vc = y.value_counts()\n",
    "keep = vc[vc >= 2].index\n",
    "mask = y.isin(keep)\n",
    "X, y = X[mask], y[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---------- Pipelines (trees: no PCA) ----------\n",
    "num_pipe = Pipeline([(\"scaler\", StandardScaler())])\n",
    "cat_enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "pre = ColumnTransformer([(\"num\", num_pipe, num_cols), (\"cat\", cat_enc, cat_cols)])\n",
    "\n",
    "rf_pipe = Pipeline([(\"pre\", pre), (\"clf\", RandomForestClassifier(random_state=42))])\n",
    "gb_pipe = Pipeline([(\"pre\", pre), (\"clf\", GradientBoostingClassifier(random_state=42))])\n",
    "\n",
    "# ---------- Compact grids (fast) ----------\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "rf_grid = {\n",
    "    \"clf__n_estimators\": [300, 500],\n",
    "    \"clf__max_depth\": [None, 20],\n",
    "    \"clf__min_samples_split\": [2, 5],\n",
    "    \"clf__min_samples_leaf\": [1, 2]\n",
    "}\n",
    "gb_grid = {\n",
    "    \"clf__n_estimators\": [150, 250],\n",
    "    \"clf__learning_rate\": [0.05, 0.1],\n",
    "    \"clf__max_depth\": [2, 3]\n",
    "}\n",
    "\n",
    "rf_search = GridSearchCV(rf_pipe, rf_grid, cv=cv, scoring=\"accuracy\", n_jobs=-1, verbose=0)\n",
    "gb_search = GridSearchCV(gb_pipe, gb_grid, cv=cv, scoring=\"accuracy\", n_jobs=-1, verbose=0)\n",
    "\n",
    "rf_search.fit(X_train, y_train)\n",
    "gb_search.fit(X_train, y_train)\n",
    "\n",
    "def evaluate(name, est):\n",
    "    y_pred = est.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Test Accuracy:\", round(acc,4))\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    return acc\n",
    "\n",
    "rf_acc = evaluate(\"RandomForest (tuned)\", rf_search.best_estimator_)\n",
    "gb_acc = evaluate(\"GradientBoosting (tuned)\", gb_search.best_estimator_)\n",
    "\n",
    "# pick best\n",
    "best_name, best_est, best_acc = (\n",
    "    (\"RandomForest (tuned)\", rf_search.best_estimator_, rf_acc)\n",
    "    if rf_acc >= gb_acc else\n",
    "    (\"GradientBoosting (tuned)\", gb_search.best_estimator_, gb_acc)\n",
    ")\n",
    "\n",
    "print(\"\\nWinner:\", best_name, \"→ Test Accuracy:\", round(best_acc,4))\n",
    "print(\"RF best params:\", rf_search.best_params_)\n",
    "print(\"GB best params:\", gb_search.best_params_)\n",
    "\n",
    "# save outputs\n",
    "pd.DataFrame([{\n",
    "    \"rf_best_params\": rf_search.best_params_,\n",
    "    \"rf_cv_best\": rf_search.best_score_,\n",
    "    \"rf_test_accuracy\": rf_acc,\n",
    "    \"gb_best_params\": gb_search.best_params_,\n",
    "    \"gb_cv_best\": gb_search.best_score_,\n",
    "    \"gb_test_accuracy\": gb_acc,\n",
    "    \"winner\": best_name,\n",
    "    \"winner_test_accuracy\": best_acc\n",
    "}]).to_csv(\"tuning_summary.csv\", index=False)\n",
    "\n",
    "joblib.dump(best_est, \"serving_pipeline_tuned.pkl\")\n",
    "print(\"\\nSaved: tuning_summary.csv, serving_pipeline_tuned.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055345f-3de6-4133-b2c8-3290a3fa64fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
